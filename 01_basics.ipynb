{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Natural Language Processing (NLP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Hey, so this is just a bunch of sentences. Corpus basically means a bunch of sentences so don't freak out! You have done a lot harder stuff and this is just a corpus. Guess this is just the new step then! \n",
    "\n",
    "HAPPY LEARNING NATURAL LANGUAGE PROCESSING!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey, so this is just a bunch of sentences. Corpus basically means a bunch of sentences so don't freak out! You have done a lot harder stuff and this is just a corpus. Guess this is just the new step then! \\n\\nHAPPY LEARNING NATURAL LANGUAGE PROCESSING!\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the corpus\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to remove the `\\n` - new line tage, we can just print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, so this is just a bunch of sentences. Corpus basically means a bunch of sentences so don't freak out! You have done a lot harder stuff and this is just a corpus. Guess this is just the new step then! \n",
      "\n",
      "HAPPY LEARNING NATURAL LANGUAGE PROCESSING!\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`N.B.`** - This did not remove the character, it is just a way of printing the output!!!\n",
    "\n",
    "\n",
    "## **TOKENIZATION**\n",
    "---\n",
    "\n",
    "Tokenizaition is the process of converting sentences into vectors `[tokens]` so as to facilitate the furthur processing of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Converting Paragraphs into Sentences** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenize converts paragraphs into sentences\n",
    "# paragraph ---> sentences\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey, so this is just a bunch of sentences.',\n",
       " \"Corpus basically means a bunch of sentences so don't freak out!\",\n",
       " 'You have done a lot harder stuff and this is just a corpus.',\n",
       " 'Guess this is just the new step then!',\n",
       " 'HAPPY LEARNING NATURAL LANGUAGE PROCESSING!']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting paragraph into sentences\n",
    "document = sent_tokenize(corpus)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, so this is just a bunch of sentences.\n",
      "Corpus basically means a bunch of sentences so don't freak out!\n",
      "You have done a lot harder stuff and this is just a corpus.\n",
      "Guess this is just the new step then!\n",
      "HAPPY LEARNING NATURAL LANGUAGE PROCESSING!\n"
     ]
    }
   ],
   "source": [
    "# printing with a loop\n",
    "for sentence in document:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Converting Paragraphs into Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paragraph ---> words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " ',',\n",
       " 'so',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'sentences',\n",
       " '.',\n",
       " 'Corpus',\n",
       " 'basically',\n",
       " 'means',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'sentences',\n",
       " 'so',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'freak',\n",
       " 'out',\n",
       " '!',\n",
       " 'You',\n",
       " 'have',\n",
       " 'done',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'harder',\n",
       " 'stuff',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'corpus',\n",
       " '.',\n",
       " 'Guess',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'the',\n",
       " 'new',\n",
       " 'step',\n",
       " 'then',\n",
       " '!',\n",
       " 'HAPPY',\n",
       " 'LEARNING',\n",
       " 'NATURAL',\n",
       " 'LANGUAGE',\n",
       " 'PROCESSING',\n",
       " '!']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizing words\n",
    "words = word_tokenize(corpus)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey\n",
      ",\n",
      "so\n",
      "this\n",
      "is\n",
      "just\n",
      "a\n",
      "bunch\n",
      "of\n",
      "sentences\n",
      ".\n",
      "Corpus\n",
      "basically\n",
      "means\n",
      "a\n",
      "bunch\n",
      "of\n",
      "sentences\n",
      "so\n",
      "do\n",
      "n't\n",
      "freak\n",
      "out\n",
      "!\n",
      "You\n",
      "have\n",
      "done\n",
      "a\n",
      "lot\n",
      "harder\n",
      "stuff\n",
      "and\n",
      "this\n",
      "is\n",
      "just\n",
      "a\n",
      "corpus\n",
      ".\n",
      "Guess\n",
      "this\n",
      "is\n",
      "just\n",
      "the\n",
      "new\n",
      "step\n",
      "then\n",
      "!\n",
      "HAPPY\n",
      "LEARNING\n",
      "NATURAL\n",
      "LANGUAGE\n",
      "PROCESSING\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Converting Paragraphs into Sentences including Punctuations!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " ',',\n",
       " 'so',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'sentences',\n",
       " '.',\n",
       " 'Corpus',\n",
       " 'basically',\n",
       " 'means',\n",
       " 'a',\n",
       " 'bunch',\n",
       " 'of',\n",
       " 'sentences',\n",
       " 'so',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'freak',\n",
       " 'out',\n",
       " '!',\n",
       " 'You',\n",
       " 'have',\n",
       " 'done',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'harder',\n",
       " 'stuff',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'corpus',\n",
       " '.',\n",
       " 'Guess',\n",
       " 'this',\n",
       " 'is',\n",
       " 'just',\n",
       " 'the',\n",
       " 'new',\n",
       " 'step',\n",
       " 'then',\n",
       " '!',\n",
       " 'HAPPY',\n",
       " 'LEARNING',\n",
       " 'NATURAL',\n",
       " 'LANGUAGE',\n",
       " 'PROCESSING',\n",
       " '!']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NTLK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
