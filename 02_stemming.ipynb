{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stemming**\n",
    "\n",
    "It is the process of reducing inflected form of a word to one so-called “stem,” or root form, also known as a “lemma” in linguistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_words = ['eating', 'slept', 'eat', 'eaten', 'sleep', 'slice', 'history', 'sliced', 'fairly', 'sportingly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Porter Stemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "slept ---> slept\n",
      "eat ---> eat\n",
      "eaten ---> eaten\n",
      "sleep ---> sleep\n",
      "slice ---> slice\n",
      "history ---> histori\n",
      "sliced ---> slice\n",
      "fairly ---> fairli\n",
      "sportingly ---> sportingli\n"
     ]
    }
   ],
   "source": [
    "for word in base_words:\n",
    "    print(word + \" ---> \" + stemming.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regular Expression Stemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_stemmer = RegexpStemmer('ing$|er$|en$',min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "eater ---> eat\n",
      "eaten ---> eat\n",
      "eats ---> eats\n"
     ]
    }
   ],
   "source": [
    "new_words = ['eating', 'eater', 'eaten', 'eats']\n",
    "for words in new_words:\n",
    "    print(words + ' ---> ' + regex_stemmer.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can clearly see, the words whose expression was declared, has been stemmed! The rest will remain as they are. the `$` sign defines which side it needs to be replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "ingeating ---> ingeat\n"
     ]
    }
   ],
   "source": [
    "# changes only to the right side\n",
    "regex_stemmer = RegexpStemmer('ing$',min=4)\n",
    "new_words = ['eating', 'ingeating']\n",
    "for words in new_words:\n",
    "    print(words + ' ---> ' + regex_stemmer.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "ingeating ---> eat\n"
     ]
    }
   ],
   "source": [
    "# changes only to all sides\n",
    "regex_stemmer = RegexpStemmer('ing',min=4)\n",
    "new_words = ['eating', 'ingeating']\n",
    "for words in new_words:\n",
    "    print(words + ' ---> ' + regex_stemmer.stem(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Snowball Stemmer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating ---> eat\n",
      "slept ---> slept\n",
      "eat ---> eat\n",
      "eaten ---> eaten\n",
      "sleep ---> sleep\n",
      "slice ---> slice\n",
      "history ---> histori\n",
      "sliced ---> slice\n",
      "fairly ---> fair\n",
      "sportingly ---> sport\n"
     ]
    }
   ],
   "source": [
    "for word in base_words:\n",
    "    print(word + \" ---> \" + snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
